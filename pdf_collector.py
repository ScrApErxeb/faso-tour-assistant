import requests
import os
import json
from datetime import datetime
import PyPDF2
from io import BytesIO

print("=" * 60)
print("üìÑ COLLECTE DE PDFs - TOURISME BURKINA FASO")
print("=" * 60)

class PDFTourismeCollector:
    def __init__(self):
        print("\n[INIT] Initialisation du collecteur PDF...")
        self.output_dir = 'data/pdfs'
        self.documents = []
        os.makedirs(self.output_dir, exist_ok=True)
        print(f"[INIT] ‚úì Dossier {self.output_dir} cr√©√©")
        
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
    
    def download_pdf(self, url, filename):
        """T√©l√©charger un PDF"""
        try:
            print(f"\n[DOWNLOAD] üì• T√©l√©chargement: {filename}")
            response = requests.get(url, headers=self.headers, timeout=30)
            
            if response.status_code == 200:
                filepath = os.path.join(self.output_dir, filename)
                with open(filepath, 'wb') as f:
                    f.write(response.content)
                
                file_size = len(response.content) / 1024  # En KB
                print(f"[DOWNLOAD] ‚úì T√©l√©charg√©: {file_size:.1f} KB")
                return filepath
            else:
                print(f"[DOWNLOAD] ‚úó Erreur HTTP {response.status_code}")
                return None
                
        except Exception as e:
            print(f"[DOWNLOAD] ‚úó Erreur: {str(e)}")
            return None
    
    def extract_text_from_pdf(self, filepath):
        """Extraire le texte d'un PDF"""
        try:
            print(f"[EXTRACT] üìñ Extraction texte...")
            with open(filepath, 'rb') as f:
                reader = PyPDF2.PdfReader(f)
                num_pages = len(reader.pages)
                
                text = ""
                for page_num, page in enumerate(reader.pages):
                    text += page.extract_text() + "\n"
                
                # Limiter √† 50000 caract√®res pour √©viter trop de donn√©es
                text = text[:50000]
                
                print(f"[EXTRACT] ‚úì {num_pages} pages extraites, {len(text)} caract√®res")
                return text, num_pages
                
        except Exception as e:
            print(f"[EXTRACT] ‚úó Erreur extraction: {str(e)}")
            return "", 0
    
    def collect_official_pdfs(self):
        """Collecter des PDFs officiels sur le tourisme burkinab√®"""
        print("\n" + "=" * 60)
        print("üèõÔ∏è COLLECTE PDFs OFFICIELS")
        print("=" * 60)
        
        # Liste de PDFs accessibles publiquement
        pdf_sources = [
            {
                'url': 'https://www.ifc.org/content/dam/ifc/doc/2024/ifc-burkina-faso-country-profile-fr.pdf',
                'filename': 'ifc_burkina_faso_profile.pdf',
                'title': 'IFC - Profil Pays Burkina Faso',
                'source': 'IFC/Banque Mondiale'
            },
            {
                'url': 'https://documents1.worldbank.org/curated/en/burkina-faso-tourism.pdf',
                'filename': 'worldbank_burkina_tourism.pdf',
                'title': 'Banque Mondiale - Secteur Touristique Burkina',
                'source': 'Banque Mondiale'
            },
            {
                'url': 'https://www.undp.org/sites/g/files/zskgke326/files/migration/bf/UNDP-BF-Tourism-Study.pdf',
                'filename': 'undp_tourism_burkina.pdf',
                'title': 'PNUD - √âtude Tourisme Burkina Faso',
                'source': 'PNUD'
            }
        ]
        
        for source in pdf_sources:
            print(f"\nüìÑ Source: {source['source']}")
            filepath = self.download_pdf(source['url'], source['filename'])
            
            if filepath and os.path.exists(filepath):
                text, num_pages = self.extract_text_from_pdf(filepath)
                
                if text:
                    self.documents.append({
                        'source': source['source'],
                        'url': source['url'],
                        'title': source['title'],
                        'content': text,
                        'filename': source['filename'],
                        'num_pages': num_pages,
                        'date_collecte': datetime.now().isoformat(),
                        'type': 'rapport_pdf',
                        'categorie': 'tourisme'
                    })
                    print(f"[SUCCESS] ‚úÖ Document ajout√© au corpus")
    
    def add_manual_pdf_instructions(self):
        """Instructions pour collecter des PDFs manuellement"""
        print("\n" + "=" * 60)
        print("üìù COLLECTE MANUELLE RECOMMAND√âE")
        print("=" * 60)
        
        manual_sources = {
            "Sites gouvernementaux burkinab√®": [
                "Minist√®re de la Culture et du Tourisme: www.culture.gov.bf",
                "Office National du Tourisme (ONTB): www.ontb.bf",
                "Minist√®re de l'√âconomie: www.finances.gov.bf"
            ],
            "Organisations internationales": [
                "UNESCO Burkina: en.unesco.org (chercher 'Burkina Faso')",
                "FAO Documents: www.fao.org/documents (chercher 'Burkina culture')",
                "Banque Africaine de D√©veloppement: www.afdb.org",
                "PNUD Burkina: www.undp.org/burkina-faso"
            ],
            "Recherche acad√©mique": [
                "Google Scholar: scholar.google.com",
                "  ‚Üí Rechercher: 'tourisme Burkina Faso filetype:pdf'",
                "  ‚Üí Rechercher: 'FESPACO culture filetype:pdf'",
                "  ‚Üí Rechercher: 'patrimoine culturel Mossi filetype:pdf'",
                "  ‚Üí Rechercher: 'artisanat Bambara filetype:pdf'",
                "ResearchGate: www.researchgate.net",
                "CAIRN: www.cairn.info"
            ],
            "Rapports ONG": [
                "Oxfam Burkina",
                "UNICEF Burkina",
                "Plan International",
                "Care International"
            ]
        }
        
        print("\nüîç SOURCES RECOMMAND√âES POUR T√âL√âCHARGEMENT MANUEL:\n")
        
        for category, sources in manual_sources.items():
            print(f"\nüìå {category}:")
            for source in sources:
                print(f"   ‚Ä¢ {source}")
        
        print("\n" + "-" * 60)
        print("üí° CONSEILS:")
        print("   1. T√©l√©charge les PDFs dans le dossier: data/pdfs/")
        print("   2. Nomme-les clairement: ex. 'ontb_rapport_2024.pdf'")
        print("   3. Relance ce script pour extraire le texte")
        print("-" * 60)
    
    def process_existing_pdfs(self):
        """Traiter les PDFs d√©j√† t√©l√©charg√©s dans data/pdfs/"""
        print("\n" + "=" * 60)
        print("üìÇ TRAITEMENT DES PDFs EXISTANTS")
        print("=" * 60)
        
        pdf_files = [f for f in os.listdir(self.output_dir) if f.endswith('.pdf')]
        
        if not pdf_files:
            print("\n[INFO] Aucun PDF trouv√© dans data/pdfs/")
            return
        
        print(f"\n[INFO] {len(pdf_files)} PDF(s) trouv√©(s)")
        
        for pdf_file in pdf_files:
            filepath = os.path.join(self.output_dir, pdf_file)
            print(f"\nüìÑ Traitement: {pdf_file}")
            
            text, num_pages = self.extract_text_from_pdf(filepath)
            
            if text:
                self.documents.append({
                    'source': 'PDF local',
                    'url': 'N/A',
                    'title': pdf_file.replace('.pdf', '').replace('_', ' '),
                    'content': text,
                    'filename': pdf_file,
                    'num_pages': num_pages,
                    'date_collecte': datetime.now().isoformat(),
                    'type': 'rapport_pdf',
                    'categorie': 'tourisme'
                })
                print(f"[SUCCESS] ‚úÖ Ajout√© au corpus")
    
    def save_data(self):
        """Sauvegarder les donn√©es extraites"""
        print("\n" + "=" * 60)
        print("üíæ SAUVEGARDE DES DONN√âES")
        print("=" * 60)
        
        if not self.documents:
            print("\n[WARNING] ‚ö†Ô∏è Aucun document √† sauvegarder")
            return 0
        
        filename = 'data/raw/pdf_corpus.json'
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(self.documents, f, ensure_ascii=False, indent=2)
            
            total_pages = sum(doc.get('num_pages', 0) for doc in self.documents)
            total_chars = sum(len(doc.get('content', '')) for doc in self.documents)
            
            print(f"\n[SAVE] ‚úì Fichier sauvegard√©: {filename}")
            print(f"[SAVE] üìä {len(self.documents)} documents")
            print(f"[SAVE] üìÑ {total_pages} pages totales")
            print(f"[SAVE] üìù {total_chars:,} caract√®res")
            
            return len(self.documents)
            
        except Exception as e:
            print(f"[SAVE] ‚úó Erreur sauvegarde: {e}")
            return 0

if __name__ == "__main__":
    collector = PDFTourismeCollector()
    
    # √âtape 1: Essayer de t√©l√©charger des PDFs publics
    collector.collect_official_pdfs()
    
    # √âtape 2: Traiter les PDFs d√©j√† t√©l√©charg√©s manuellement
    collector.process_existing_pdfs()
    
    # √âtape 3: Afficher instructions pour collecte manuelle
    collector.add_manual_pdf_instructions()
    
    # √âtape 4: Sauvegarder
    total = collector.save_data()
    
    print("\n" + "=" * 60)
    print(f"‚úÖ COLLECTE TERMIN√âE: {total} documents PDF")
    print("=" * 60)
    print("\nüí° PROCHAINE √âTAPE:")
    print("   T√©l√©charge manuellement des PDFs et relance ce script")
    print("=" * 60)n